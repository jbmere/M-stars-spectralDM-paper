The objective addressed in this Section is to develop an automated
procedure to identify spectral bands that yield good atmospheric
temperature, gravity and metallicity (hereafter physical parameters)
diagnostics for M type stars. Given the lack of a calibration set of
benchmark stars with observed spectra and homogeneous coverage of the
space of physical parameters, we must turn to synthetic libraries of
spectra. Furthermore, only temperatures and gravities can be
calibrated independently of the spectra \citep[for example as
in][using interferometry]{2003A&A...397L...5S}: all metallicity
estimates in the literature are based on collections of synthetic
spectra, and therefore spectral synthesis codes are the only resource
to construct regression models. Even in the case of interferometry,
the estimates of radii (and therefore gravity) depend on stellar
models (although less strongly) via the limb darkening corrections.

As an alternative to the methods based on genetic algorithms used in
this work, the atomic or molecular line/band parameters can be used in
principle to select the spectral features that are more sensitive to
changes in the physical parameters as
in \cite{2016A&A...587A..19P}. However, the suitability of spectral
features as diagnostics of the stellar atmospheric properties depends
not only on the individual behaviour of each line/band, but also on
the relative properties of neighbouring features in the same spectral
region, that may overlap depending on the spectral
resolution. Furthermore, good spectral diagnostics at a given
signal-to-noise ratio (SNR) may show a severely degraded predictive
power in the low SNR regime. Therefore, we propose an alternative
selection approach that takes the resolution and SNR ratio into
account, to assess the utility of spectral features for the task of
inferring physical atmospheric parameters. 

In the following, we adopt the BT-Settl library of synthetic spectra
(\cite{2013MSAIS..24..128A}) as the framework where spectral
diagnostics will be searched for. These synthetic spectra were
pre-processed in several steps as described below.

\subsection{Spectral preprocessing}

First, and in order to define good temperature diagnostics, spectra
between 2000 and 4200K in steps of 100 K were selected, with $\log(g)$
in the range between 4 and 6 dex (when g is expressed in cm/s$^{-2}$),
in steps of 0.5 dex. The metallicity of the representative spectra was
restricted to the set 0, 0.5 and -1 dex.  This yields a total set size
of 535 available spectra.

A series of preprocessing steps were then carried out in order to
match the spectral resolution and wavelength coverage and sampling of
the synthetic library to that of the collection of observed spectra
(IPAC or IRTF, see below). This required the definition of a common
wavelength range present in all available observed spectra, and the
subsequent trimming to match that range. A unique wavelength sampling
was also defined and all spectra (synthetic and observed) interpolated
to match the sampling. Finally, all spectra, both synthetic and
observed were divided by the integrated flux in order to factor out
the stellar distance.

In order to avoid selecting spectral features that are good predictors
only in the unrealistic SNR=$\infty$ regime, the search for optimal
diagnostics of the atmopheric parameters of M stars was carried out
for three SNR values (10, 50 and $\infty$) by degrading the synthetic
spectra with Gaussian noise of zero mean. These values were found to
be sufficient in a wide range of experiments carried out in parallel
and described in \cite{}. The special SNR=$\infty$ case has been
retained for the sake of completeness although \cite{} show that
training sets derived from noiseless spectra are, at best,
unnecessary, and at worst damage performance severely. 

\subsection{Feature definition and selection}
\label{subsec:FD}

As mentioned in Sect. \ref{sec:intro}, defining good spectral
diagnostics for the prediction of atmospheric physical parameters of M
stars is an extremely difficult task .

The work in \cite{cesetti} defined wavelength regions in the I and K
bands optimal for the diagnostic of physical parameters based on the
sensitivity exhibited by the flux emitted in these segments to changes
of the physical parameters. The sensitivity was measured in terms of
the derivative of the flux with respect to the physical parameter. The
approach adopted here is to select spectral features that yield the
best accuracy when used as predictive variables in a regression model
that estimates the stellar atmospheric physical parameters ($T_{eff}$,
$\log(g)$ and metallicity). The evaluation of the accuracy of the
estimates produced from a subset of features is described further
below. We consider the effective temperature as the dominant parameter
influencing changes in the stellar spectra (a strong feature) and
thus, it was estimated first, and then used as input in the regression
models for the gravity and metalicity.

Here, a feature $F$ is defined as

\begin{equation}\label{eq:featureDefinition}
  F = \int_{\lambda_{1}}^{\lambda_{2}} (1-\frac{f(\lambda)}{F_{cont}} \cdot {\rm d}{\lambda})
\label{eq:featuredef}
\end{equation}

where $f(\lambda)$ denotes the normalized flux from the star at
wavelength $\lambda$, and where $F_{cont}$ is the average flux in a
spectral band between $\lambda_{cont;1}$ and $\lambda_{cont;2}$. We
explain below how we search for the band definitions that produce
physical parameter predictions with the smallest errors.

Another type of features defined as

\begin{equation}\label{eq:feature2}
  F' = \frac{ \int_{\lambda_{1}}^{\lambda_{2}}f(\lambda) \cdot {\rm d}{\lambda}}
               {\int_{\lambda_{3}}^{\lambda_{4}} f(\lambda) \cdot {\rm d}{\lambda}} 
\end{equation}

were considered, where $\lambda_1, \lambda_2, \lambda_3$, and
$\lambda_4$ delimit two spectral bands such that the ratio of the
integrated fluxes in the two bands is hoped to be a good predictor
(alone or in combination with other features) of the star atmospheric
physical parameters. The results obtained with this alternative
feature definition did not differ significantly on average from the
ones observed with the one adopted in Eq. \ref{eq:featureDefinition},
and including them here would result in an excessively lengthy
paper. In view of the equivalent global performances, we preferred the
former because it allows direct comparison with the features proposed
by \cite{cesetti}.

We used Genetic Algorithms (hereafter GAs) to solve the optimization
problem described above, that is, the problem of finding the features
(band boundaries) that minimize the prediction error of a regression
estimate of the physical parameters. We used the implementation of
genetic algorithms publicly available as the R \citep{R2013} GA
package. The concept of using in-silico evolution for the solution of
optimization problems was introduced
by \cite{holland1975adaptation}. Although its application is now
reasonably widespread \citep[see e.g. ]{goldberg1989genetic}), they
became very popular only when sufficiently powerful computers became
available. GAs were presented to the astronomical community
in \cite{1995ApJS..101..309C}, and have been used extensively in the
past \citep[see][for the last application of GAs in astronomy at the
time of writing]{}.

For the sake of simplicity let us define Genetic Algorithms (GAs) as
search algorithms that are based on the principle of evolution by
natural selection. The procedure works by evolving in the sense
explained below, chromosomes (in our case, sets of spectral features
as defined by Eq. \ref{eq:featuredef}) from an initial random
population. Evolution proceeds via cycles of differential replication,
recombination and mutation of the fittest chromosomes. The concept of
fittest is context dependent, but in our case fitness is defined in
relation with the accuracy with which a given chromosome (a set
$\{F_i\}$ of spectral features) predicts the physical parameters.

The data set used to search for the optimal set of spectral features
will be, as mentioned before, the BT Settl collection of synthetic
spectra, where each spectrum is tagged with the effective temperature,
gravity and metallicity of the model atmosphere from which the
spectrum emerged.

The implementation of the GA comprises the following steps:

\begin{itemize}
\item \textbf{Stage 1}:{Definition of the population of
potential features (chromosomes).}

\item \textbf{Stage 2}:{Each chromosome in the population
is evaluated by its ability to predict the physical parameters of each
star in the dataset (fitness function). }

\item \textbf{Stage 3}:{Stage 3: Chromosome selection. The new
generation of individuals is initialised by tranferring a number of
the most fitted ones in the previous generation. The percentage of
individuals transferred is known as the degree of elitism. }

\item \textbf{Stage 4}:{The population of chromosomes is replicated. 
 Chromosomes with higher fitness scores will generate more numerous
 offspring.}

\item \textbf{Stage 5}:{The genetic information contained in
the replicated parent chromosomes is combined through genetic
crossover. Two randomly selected parent chromosomes are used to create
two new chromosomes.}

\item \textbf{Stage 6}:{Mutations are then introduced in the
chromosome randomly. These mutations produce new genes used in
chromosomes.  Steps 5 and 6 are applied over the chromosomes
established at Step 4.}

\item \textbf{Stage 7}:{This process is repeated from Stage 2 until 
a target accuracy is achieved or the maximum number of iterations is
attained.}

\end{itemize}

We test features defined by bands (the numerator and denominator of
Eq. \ref{eq:featureDefinition}) that comprise ten consecutive bins
(fluxes) of a spectrum. The bands tested in different features may
overlap by as much as 5 consecutive bins (which in practice implies
that we define the first feature as the spectral chunk between
wavelength bins $i=1$ and $i=10$, the second feature between bins
$i=6$ and $i=15$, the third feature between bins $i=11$ and $i=20$,
etc). The spectral bands in the numerator and denominator of a test
feature cannot overlap.

It would be possible to evaluate the predictive performance of
individual features defined with Eq. \ref{eq:featuredef}. An obvious
conceptual limitation of this univariate approach (considering
chromosomes that code a single predictive feature) would be the lack
of consideration that features work in the context of interconnected
pathways and, therefore, it is their behavior as a group that has to
be evaluated in terms of the predictive accuracy. In other words, a
single feature can yield a poor predictive performance alone, but
improve very significantly the predicton accuracy when used in
combination with other features. Multivariate selection methods thus
seem more suitable for the analysis of the regressors since variables
are tested in combination to identify interactions between
features. In this work we define a chromosome as a set of ten
individual genes, and each gene codes a pair of non-overlapping
spectral bands, the ratio of which is used as predictor of the
physical parameters according to (\ref{eq:featureDefinition}).

The population size was set to 8000 individuals and the maximum number
of accepted iterations set to 4000. We produced three randomly started
populations so as to provide enough initial variety. The crossover and
mutation probabilities were set to 0.85 and 0.35 respectively. Elitism
was fixed to 0.15. We used a binary codification of the chromosomes
and a parallel implementation of the GA in a farm of fifteen computers
per physical parameter \footnote{All computations needed for this work
were carried out in the CeSViMa (http://www.cesvima.upm.es/) power7
HPC which involves processors with 8 cores and four threads per core,
running at 3,3 GHz and with 32Gb of RAM each.

Feature fitness was defined in terms of the Akaike Information
Criterion (AIC) for linearity between the potential feature against
the physical parameter.{bf TODO: RMSE? Why AIC?}  

It is important to stress that the regression model used to evaluate
the fitness of the feature sets (chromosomes) is not the same model
that will be used in practice to predict physical parameters for
observed spectra as described in Section \ref{ssub:models} below. For
fitness evaluation in the GA we used a simple multilinear model for
the sake of speed, given the extreme size of the search space of all
possible combinations of 10 spectral features. In the IRTF context,
these 10 features in each chromosome are selected amongst the roughly
6000 potential features. This is $\binom{6000}{10}$ which has an order
of magnitude of $10^{24}$. 

The GA procedure provides us with a large collection of chromosomes,
each one of them consisting of ten spectral features.  Although these
are all potential solutions of the problem, it is not immediately
clear which one should be selected for the final regression model. In
this work we have selected the most frequent features amongst the
fittest chromosomes as predictive variables of the physical parameters
in regression models. Features appearing in less than five chromosomes
were initially discarded as they can not be relevant by themselves and
just arise randomly by combination with other stronger chromosomes.

{\bf TODO: Rewrite} It is relevant to say that when genes of a
chromosome induced as ratio of two gaussian variables have extremely
wide wings if any of the features is centered around zero, the fitness
criteria removes it as a cadidate feature as it is not able to explain
the physical parameter.  Therefore, the single regression model
should, to some extent, be descriptive of the population. The simpler
strategy would be to use the frequency of the chromosome in the
population as criterion for inclusion in a forward selection
strategy. However we prefered to select the features based on their
highest fitness as it enhances the value of the direct contribution to
explain the physical parameter.  As we have accepted that compex
interactions between individual features are possible, it was selected
a fixed number of features allowing both, enough room for developping
those complex dependency relationships but to keep the complexity of
the comming regression models under control.  Therefore, it was
selected ten as the suitable number of features being considered per
physical parameter.

Once the GA has generated a proposal set of features for predicting
each of the physical parameters, the next step consists in training
the regression model based on these features. This is described in the
nest Section.

\subsection{Models considered.}
\label {ssub:models}

Once a feature set (the predictor variables) was selected from the
output of the GA, we construct regression models to predict the
physical parameters (response or predicted variables) from it. In the
context of Machine Learning, constructing a regression model consists
in using a training set (a set of cases defined by the predictor
variables for which the predicted variables are available) to infer
the parameters of an (often analytical) mapping between predictor and
predicted variables. The regression model parameters should not be
confused with the physical parameters of the atmosphere we aim at
inferring. {\bf TODO: Check if every occurrence of parameter is clear}

In this case, our training set is again the BT Settl collection of
synthetic spectra, for which we already computed the predictor
variables (the features) as part of the GA selection procedure. And,
of course, for each spectrum we also have available the effective
temperature, the gravity and the metallicity. Once the model is
trained, we will apply it to observed spectra as described in
Sections \ref{sec:irtf} and \ref{sec:ipac}.  

Several regression models are trained for the prediction of each
physical parameter in order to evaluate their performance:

\begin{itemize}

\item {Bagging with Multiadaptive Spline Regression Models \emph{(hereafter MARS)}.}

\item {Random Forest Regression Models \emph{(RF)}.}

\item {$k$-Nearest Neighbours \emph{(KNN)}.}

\item {Generalized Boosted Regression Models \emph{(GBM)}.}

\item {Support Vector Regression with Gaussian Kernel \emph{(SVR)}.}

\item {Multi-layer Perceptron Neural Networks \emph{(NNET)}.}

\item {Kernel Partial Least Squares Regression \emph{(KPLS)}.}

\item {Rule Regression Models \emph{(RR)}.}

\end{itemize}

In order to assess the validity of our feature sets we also compare
the predictions based on them with other input spaces. In particular,
we also compute physical parameters that yield the the minimum
$\chi^2$, and train a Projection Pursuit regression models with the
Independent Components derived from each spectrum. {\bf TODO: add
reference for ICA}.

Including here a sufficient description of each and every regression
model that we trained would render the manuscript excessively lengthy
but interested readers can find additional information in
\cite{baraud2002model,geman1992neural,elith2008working,meyer2003support,svetnik2003random}. Suffice it to say that each one of them can be thought of as
a parametric model that predicts one physical parameter from an input
vector. The input vector can be the full normalised spectrum, the ICA
lower-dimensional representation of the full spectrum, the spectral
features selected by \cite{cesetti} or those selected by the GA. The
regression model parameters are infered (using strategies that differ
from one regression model to the other) from a set of examples. As
explained above, this set of examples (spectra of stars for which we
know the physical parameters) is called the training set, and the
process by which the model parameters are determined from the training
set, is called training of the model. In the next paragraph we give
minimal details of each regression model trained, and references for
the interested reader.

In order to avoid the well known problem of overfitting \cite[see
e.g.][]{Dietterich:1995:OUM:212094.212114}, we use five-fold
cross-validation to estimate the prediction errors. $n$-fold cross
validation consists in dividing the trainins set into $n$ disjoint
subsets and training ten different regression models, each one of them
with ($n$-1) of the $n$ subsets. The $n$-th subset not used for
training is used to estimate the errors.

As every type of model has its own set of tunable parameters as well
as its own training procedure, the authors have selected a common
R \cite{R2016} wrapper for all models named caret (short for
Classification And REgression Training) \cite{caret}.  This wrapper
enables a common interface, as well as the use of the same set of
training/set samples for the adopted five-fold cross-validation error
estimation. As explained above, each regression model has its own set
of model parameters. For each model we have searched for the parameter
set that minimized the Root Mean Square Error (RMSE) in a grid of
values defined {\it ad hoc} for each technique.

The adopted procedure for learning the models can then be summarized
as the pseudocode \ref{caretp}.

{\bf TODO [Joaquín]: define each element in the pseudocode}

\begin{pseudocode}[shadowbox]{Model Learning}{DataSet,ParRanges}
\label{caretp}
 \mathcal{S}_{ModelParameters} \GETS ParRanges \\
 \mathcal{S}_{DataFolders} \GETS Preprocess(DataSet) \\ 
 \FOREACH x \in \mathcal{S}_{ModelParameters} \DO
  \BEGIN
    \FOREACH z \in \mathcal{S}_{DataFolders} \DO
      \BEGIN
	HDS(z) \GETS \mbox{Hold-out specific samples} \\
	Model(z) \GETS Fits(\mathcal{S}_{DataFolders} \setminus HDS(z) ) \\
	Perf(z) \GETS Predicts(Model(z),HDS(z)) \\
      \END \\
    Perf(x) \GETS Average(Perf(z)) \quad \forall z \in \mathcal{S}_{DataFolders} \\
  \END \\
  
  OPS \GETS argmax(Perf(y)) \quad \forall y \in \mathcal{S}_{Modelparameters} \\
  Model \GETS Fits(DataSet, OPS) \\
\end{pseudocode}

As mentioned above, the training set was constructed from the BT Settl
library of stellar spectra. The interested reader may find different
approaches in the literature to the problem of finding an optimal set
of training examples. \cite{hoggCannon} for example prefer to use real
observed spectra rather than synthetic libraries to create a
generative model in which the individual spectral fluxes are modelled
as second degree polynomials with the physical parameters as
arguments. The real observed spectra have physical parameters taken
from the literature, which in turn are almost always inferred using
synthetic spectral libraries. In our opinion, this approach does not
solve the dependence of the predicted parameters on the necessarily
imperfect synthetic libraries, but has the advantage that the relative
frequencies of examples in the training set represents better the
biases naturally encountered in surveys than the uniform sampling of
parameter space found in synthetic libraries. Recently, \cite{heiter}
have started a program to compile a set of stars with accurate
physical parameter determinations infered independently of
spectroscopic measurements and atmospheric models (as much as
possible). Unfortunately, this ambitious program only contains 34
stars of spectral types F, G, and K. In the M regime we find similar
approaches in \cite{2014AJ....147...47B} and references therein, where
the atmospheric parameters are derived using interferometric
measurements of stellar radii. Again, this only amounts to a very
small number (21 K and M stars) of examples and a very sparse sampling
of the parameters space.

All efforts to compile training sets of stars with accurate,
homogeneous, and reliable physical parameters derived independently of
spectroscopic measurements are valuable not only because they allow
for the improvement of the stellar atmospheric models but also because
they help increase the reliability of the regression models by making
them independent of these atmospheric models. But until these training
sets with sufficient and homogeneous sampling of the parameter space
are available, we must turn to the use of synthetic libraries.

% Additional text

%In order to assess the
%performance of the regression models, we compare their predictions
%with i) values of the physical parameters from the literature (when
%available); ii) the predictions from the popular $minimum \chi^2$
%distance to spectra in the BT-Settl library.
%;
%iii) parameter predictions based on a projection pursuit regression
%model {\bf Is this correct, Joaquín? Somewhere in your first version
%of the paper it was stated that the ICA components were fed to an SVM
%with C=10 and epsilon=0.001 for temperature, and different values for
%logg and metallicity} trained with projections of the BT-Settl spectra
%onto the set of vectors resulting from an Independent Component
%Analysis (ICA); and finally, iv) predictions from a regression model
%trained with the features proposed by \cite{cesetti} (only for the
%IRTF spectra) {\bf Joaquín, aquí necesitamos explicar qué tipo de
%modelo entrenamos con las features de cesetti.}.
%In the case of features proposed by \cite{cesetti}, such ranges were
%directly provided by their paper and the GA based selection of features 
%was, therefore, not needed.

%It is worthy to said that because of the impact on the emission spectrum 
%for all the pohysical parameters are the same, several strategies were 
%implemented to verify to what end using hierarchical knowledge becomes
%helpful to the modelling procedure. Therefore, extensive set of trials 
%have been conducted to derive gravity and metallicity features with and
%without temperature knowledge. Models were trained to determine the impact of
%such temperature hierarchical contribution and it was found that, 
%no matter of the model considered, the features determined plus the 
%estimated star temperature outperform the same model without the 
%temperature knowledge by about 20\% in case of gravity models and 12\%
%in case of metallicity models.
%Based on those results, GA features for gravity and netallicity were 
%reinforced with the estimated star temperature as an additional feature.
